{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-Document Summary Metadata Pack"
   ],
   "id": "40daac73-de30-4a5d-b57b-6089b99190f0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This LlamaPack provides an advanced technique for injecting each chunk with “sub-document” metadata. This context augmentation technique is helpful for both retrieving relevant context and for synthesizing correct answers.\n",
    "\n",
    "It is a step beyond simply adding a summary of the document as the metadata to each chunk. Within a long document, there can be multiple distinct themes, and we want each chunk to be grounded in global but relevant context.\n",
    "\n",
    "Source: https://github.com/run-llama/llama_index/blob/main/llama-index-packs/llama-index-packs-subdoc-summary/examples/subdoc-summary.ipynb Video: https://www.youtube.com/watch?v=m6P1Rp91AzM&t=1s"
   ],
   "id": "8dd0acdb-5aec-4129-8772-81f56d6b25cf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Data"
   ],
   "id": "66818da6-a3fb-4537-b30a-922a8a0ef99e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "811.82s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "817.00s - pydevd: Sending message related to process being replaced timed-out after 5 seconds"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 13.0M  100 13.0M    0     0  27.7M      0 --:--:-- --:--:-- --:--:-- 28.0M"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/'\n",
    "!curl 'https://arxiv.org/pdf/2307.09288.pdf' -o 'data/llama2.pdf'"
   ],
   "id": "317a3207-1211-4a6a-bd7d-3ab14f399951"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()"
   ],
   "id": "bf6ab9c0-c993-4ab2-8343-b294676d7550"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Sub-Document Summary Metadata Pack"
   ],
   "id": "98bfbe4b-539c-469c-82e6-1f823f28d5f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-packs-subdoc-summary llama-index-llms-openai llama-index-embeddings-openai"
   ],
   "id": "af4b815e-f5ce-406b-9dcb-5a23fc9f96db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.packs.subdoc_summary import SubDocSummaryPack\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "subdoc_summary_pack = SubDocSummaryPack(\n",
    "    documents,\n",
    "    parent_chunk_size=8192,  # default,\n",
    "    child_chunk_size=512,  # default\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\"),\n",
    "    embed_model=OpenAIEmbedding(),\n",
    ")"
   ],
   "id": "d619362b-ae45-4e47-b400-1c2ce7262496"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "response = subdoc_summary_pack.run(\"How was Llama2 pretrained?\")\n",
    "display(Markdown(str(response)))\n",
    "for n in response.source_nodes:\n",
    "    display_source_node(n, source_length=10000, metadata_mode=\"all\")"
   ],
   "id": "fb11a60d-d356-40c5-84c1-4135382bfbfd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "response = subdoc_summary_pack.run(\n",
    "    \"What is the functionality of latest ChatGPT memory.\"\n",
    ")\n",
    "display(Markdown(str(response)))\n",
    "\n",
    "for n in response.source_nodes:\n",
    "    display_source_node(n, source_length=10000, metadata_mode=\"all\")"
   ],
   "id": "1181af9d-680f-4ba3-89e2-f88b12a89cc7"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
